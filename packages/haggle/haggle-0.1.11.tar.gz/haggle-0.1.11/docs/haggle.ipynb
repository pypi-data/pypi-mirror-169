{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Haggle\" data-toc-modified-id=\"Haggle-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Haggle</a></span></li><li><span><a href=\"#Simple-example\" data-toc-modified-id=\"Simple-example-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Simple example</a></span><ul class=\"toc-item\"><li><span><a href=\"#By-the-way...\" data-toc-modified-id=\"By-the-way...-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>By the way...</a></span></li></ul></li><li><span><a href=\"#Search-results-and-dataset-metadata\" data-toc-modified-id=\"Search-results-and-dataset-metadata-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Search results and dataset metadata</a></span><ul class=\"toc-item\"><li><span><a href=\"#.meta\" data-toc-modified-id=\".meta-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>.meta</a></span></li><li><span><a href=\"#Cached-search-info\" data-toc-modified-id=\"Cached-search-info-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Cached search info</a></span></li></ul></li><li><span><a href=\"#The-boring-stuff\" data-toc-modified-id=\"The-boring-stuff-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>The boring stuff</a></span><ul class=\"toc-item\"><li><span><a href=\"#Install\" data-toc-modified-id=\"Install-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Install</a></span></li><li><span><a href=\"#API-credentials\" data-toc-modified-id=\"API-credentials-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>API credentials</a></span></li></ul></li><li><span><a href=\"#F.A.Q.\" data-toc-modified-id=\"F.A.Q.-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>F.A.Q.</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-if-I-don't-want-a-zip-file-anymore?\" data-toc-modified-id=\"What-if-I-don't-want-a-zip-file-anymore?-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>What if I don't want a zip file anymore?</a></span></li><li><span><a href=\"#Do-you-have-any-jupyter-notebooks-demoing-this.\" data-toc-modified-id=\"Do-you-have-any-jupyter-notebooks-demoing-this.-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Do you have any jupyter notebooks demoing this.</a></span></li></ul></li><li><span><a href=\"#Scrap\" data-toc-modified-id=\"Scrap-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Scrap</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple facade to [Kaggle](https://www.kaggle.com/) data.\n",
    "\n",
    "Essentially, instantiate a `KaggleDatasets` object, and from it...\n",
    "- search for datasets from the python console (so much better than having pictures the [kaggle website](https://www.kaggle.com/) right?)\n",
    "- download what you want and start using...\n",
    "- ... oh, and it automatically caches the data zip and search results to local files\n",
    "- ... oh, and all the while it pretends to be a humble dict with `owner/dataset` keys, and that's the coolest bit.\n",
    "\n",
    "**Haggle:** /ˈhaɡəl/\n",
    "- an instance of intense argument (as in bargaining) \n",
    "- wrangle (over a price, terms of an agreement, etc.) \n",
    "- rhymes with Kaggle and is not taken on pypi (well, now it is)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:25:57.347691Z",
     "start_time": "2020-09-23T17:25:56.900121Z"
    }
   },
   "outputs": [],
   "source": [
    "from haggle import KaggleDatasets\n",
    "\n",
    "rootdir = '/D/Dropbox/_odata/kaggle'  # define where you want the data to be cached/downloaded\n",
    "\n",
    "s = KaggleDatasets(rootdir)  # make an instance\n",
    "\n",
    "if 'rtatman/english-word-frequency' in s:\n",
    "    del s['rtatman/english-word-frequency']  # just to prepare for the demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:25:58.269000Z",
     "start_time": "2020-09-23T17:25:58.245498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uciml/human-activity-recognition-with-smartphones',\n",
       " 'sitsawek/phonetics-articles-on-plos']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s)  # see what you have locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search something (you can also search on [kaggle](https://www.kaggle.com/), I was kidding about it being lame!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:26:05.778129Z",
     "start_time": "2020-09-23T17:26:00.303387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(results)=180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rtatman/english-word-frequency',\n",
       " 'yekenot/fasttext-crawl-300d-2m',\n",
       " 'rtatman/japanese-lemma-frequency',\n",
       " 'rtatman/glove-global-vectors-for-word-representation',\n",
       " 'averkij/lingtrain-hungarian-word-frequency',\n",
       " 'lukevanhaezebrouck/subtlex-word-frequency',\n",
       " 'facebook/fatsttext-common-crawl',\n",
       " 'facebook/fasttext-wikinews',\n",
       " 'facebook/fasttext-english-word-vectors-including-subwords',\n",
       " 'kushtej/kannada-word-frequency']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = s.search('word frequency')\n",
    "print(f\"{len(results)=}\")\n",
    "list(results)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose what you want? Good, now do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:26:09.951448Z",
     "start_time": "2020-09-23T17:26:07.515926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "py2store.slib.s_zipfile.ZipReader"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = s['rtatman/english-word-frequency']\n",
    "type(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's slow down a moment. What happened? What's this `ZipReader` thingy?\n",
    "\n",
    "Well, what happened is that this downloaded the zip file of the data for you and saved it in `ROOTDIR/rtatman/english-word-frequency.zip`. Don't believe me? Go have a look. \n",
    "\n",
    "But then it also returns this object called `ZipReader` that points to it. \n",
    "\n",
    "If you don't like it, you don't have to use it. But I think you should like it.\n",
    "\n",
    "Look at what it can do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the contents of file (that's in the zip... okay there's just one here, it's a bit boring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:26:09.971593Z",
     "start_time": "2020-09-23T17:26:09.953309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unigram_freq.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the data for any given file of the zip without ever having to unzip it!\n",
    "\n",
    "Oh, and still pretending to be a dict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:26:10.183257Z",
     "start_time": "2020-09-23T17:26:10.134735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b is a <class 'bytes'> and has 4956252 bytes\n"
     ]
    }
   ],
   "source": [
    "b = v['unigram_freq.csv']\n",
    "print(f\"b is a {type(b)} and has {len(b)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is given in bytes by default, since that's the basis of everything. \n",
    "\n",
    "From there you can go everywhere. Here for example, say we'd like to go to `pandas.DataFrame`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:26:11.463281Z",
     "start_time": "2020-09-23T17:26:11.253842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333333, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "df = pd.read_csv(BytesIO(b))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:26:11.956916Z",
     "start_time": "2020-09-23T17:26:11.933968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  word        count\n",
      "0  the  23135851162\n",
      "1   of  13151942776\n",
      "2  and  12997637966\n",
      "3   to  12136980858\n",
      "4    a   9081174698\n",
      "5   in   8469404971\n",
      "6  for   5933321709\n"
     ]
    }
   ],
   "source": [
    "print(df.head(7).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as mentioned, it caches the data to your local drive. You know, download, so that the next time you ask for `s['rtatman/english-word-frequency']`, it'll be faster to get those bytes.\n",
    "\n",
    "See, let's list the contents of `s` again and see that we now have that `'rtatman/english-word-frequency'` key we didn't have before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:26:13.319983Z",
     "start_time": "2020-09-23T17:26:13.300472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uciml/human-activity-recognition-with-smartphones',\n",
       " 'rtatman/english-word-frequency',\n",
       " 'sitsawek/phonetics-articles-on-plos']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By the way..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So a `KaggleDatasets` is a store with a dict-like interface. \n",
    "\n",
    "Listing happens locally. Remote listing is done through `.search(...)`.\n",
    "\n",
    "Getting happens locally first, and if not, will get remotely (and cache locally).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where are the zips stored? Ask `.zips_dir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:27:57.840230Z",
     "start_time": "2020-09-23T17:27:57.822470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/D/Dropbox/_odata/kaggle/zips'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.zips_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search results and dataset metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at those search results. All we did is a `len(results)` and a `list(results)`. What else can you do with that object?\n",
    "\n",
    "Well, as is so happens, you can do whatever (read-only) operation you can do on a -- take a wild guess -- a dict. \n",
    "\n",
    "Namely, you can get a value for the keys we've listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:26:47.546170Z",
     "start_time": "2020-09-23T17:26:47.513767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creatorName': 'Rachael Tatman',\n",
      " 'creatorUrl': 'rtatman',\n",
      " 'currentVersionNumber': 1,\n",
      " 'description': None,\n",
      " 'downloadCount': 3079,\n",
      " 'files': [],\n",
      " 'id': 2367,\n",
      " 'isFeatured': False,\n",
      " 'isPrivate': False,\n",
      " 'isReviewed': True,\n",
      " 'kernelCount': 12,\n",
      " 'lastUpdated': '2017-09-06T18:21:27.18Z',\n",
      " 'licenseName': 'Other (specified in description)',\n",
      " 'ownerName': 'Rachael Tatman',\n",
      " 'ownerRef': 'rtatman',\n",
      " 'ref': 'rtatman/english-word-frequency',\n",
      " 'subtitle': '⅓ Million Most Frequent English Words on the Web',\n",
      " 'tags': [{'competitionCount': 3,\n",
      "           'datasetCount': 231,\n",
      "           'description': 'Language is a method of communication that consists '\n",
      "                          'of using words arranged into meaningful patterns. '\n",
      "                          'This is a good place to find natural language '\n",
      "                          'processing datasets and kernels to study languages '\n",
      "                          'and train your chat bots.',\n",
      "           'fullPath': 'topic > culture and humanities > languages',\n",
      "           'isAutomatic': False,\n",
      "           'name': 'languages',\n",
      "           'ref': 'languages',\n",
      "           'scriptCount': 77,\n",
      "           'totalCount': 311},\n",
      "          {'competitionCount': 6,\n",
      "           'datasetCount': 445,\n",
      "           'description': 'The linguistics tag contains datasets and kernels '\n",
      "                          'that you can use for text analytics, sentiment '\n",
      "                          'analyses, and making clever jokes like this: Let me '\n",
      "                          \"tell you a little about myself. It's a reflexive \"\n",
      "                          'pronoun that means \"me.\"',\n",
      "           'fullPath': 'topic > people and society > social science > '\n",
      "                       'linguistics',\n",
      "           'isAutomatic': False,\n",
      "           'name': 'linguistics',\n",
      "           'ref': 'linguistics',\n",
      "           'scriptCount': 122,\n",
      "           'totalCount': 573},\n",
      "          {'competitionCount': 18,\n",
      "           'datasetCount': 4172,\n",
      "           'description': 'An interconnected network of tubes that connects '\n",
      "                          'the entire world together. This tag covers a broad '\n",
      "                          'range of tags; anything from cryptocurrency to '\n",
      "                          'website analytics.',\n",
      "           'fullPath': 'topic > science and technology > internet',\n",
      "           'isAutomatic': False,\n",
      "           'name': 'internet',\n",
      "           'ref': 'internet',\n",
      "           'scriptCount': 198,\n",
      "           'totalCount': 4388}],\n",
      " 'title': 'English Word Frequency',\n",
      " 'topicCount': 1,\n",
      " 'totalBytes': 2236581,\n",
      " 'url': 'https://www.kaggle.com/rtatman/english-word-frequency',\n",
      " 'usabilityRating': 0.8235294,\n",
      " 'versions': [],\n",
      " 'viewCount': 21726,\n",
      " 'voteCount': 105}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(results['rtatman/english-word-frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get description, size, tags, download count... Useful stuff to make your choice. \n",
    "\n",
    "Personally, I like transform those results in a `DataFrame` that I can subsequently interrogate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:26:51.335317Z",
     "start_time": "2020-09-23T17:26:51.292688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>totalBytes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jealousleopard/goodreadsbooks</th>\n",
       "      <td>Goodreads-books</td>\n",
       "      <td>comprehensive list of all books listed in good...</td>\n",
       "      <td>23640</td>\n",
       "      <td>6.373380e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uciml/zoo-animal-classification</th>\n",
       "      <td>Zoo Animal Classification</td>\n",
       "      <td>Use Machine Learning Methods to Correctly Clas...</td>\n",
       "      <td>16597</td>\n",
       "      <td>1.898000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yekenot/fasttext-crawl-300d-2m</th>\n",
       "      <td>FastText crawl 300d 2M</td>\n",
       "      <td>2 million word vectors trained on Common Crawl...</td>\n",
       "      <td>8275</td>\n",
       "      <td>1.545552e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rtatman/sentiment-lexicons-for-81-languages</th>\n",
       "      <td>Sentiment Lexicons for 81 Languages</td>\n",
       "      <td>Sentiment Polarity Lexicons (Positive vs. Nega...</td>\n",
       "      <td>7960</td>\n",
       "      <td>1.621755e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rtatman/glove-global-vectors-for-word-representation</th>\n",
       "      <td>GloVe: Global Vectors for Word Representation</td>\n",
       "      <td>Pre-trained word vectors from Wikipedia 2014 +...</td>\n",
       "      <td>7432</td>\n",
       "      <td>4.801726e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mozillaorg/common-voice</th>\n",
       "      <td>Common Voice</td>\n",
       "      <td>500 hours of speech recordings, with speaker d...</td>\n",
       "      <td>6075</td>\n",
       "      <td>1.293147e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arathee2/demonetization-in-india-twitter-data</th>\n",
       "      <td>Demonetization in India Twitter Data</td>\n",
       "      <td>Data extracted from Twitter regarding the rece...</td>\n",
       "      <td>5761</td>\n",
       "      <td>9.195780e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eibriel/rdany-conversations</th>\n",
       "      <td>rDany Chat</td>\n",
       "      <td>157 chats &amp; 6300+ messages with a (fake) virtu...</td>\n",
       "      <td>3983</td>\n",
       "      <td>9.167240e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrisdal/2016-us-presidential-debates</th>\n",
       "      <td>2016 US Presidential Debates</td>\n",
       "      <td>Full transcripts of the face-off between Clint...</td>\n",
       "      <td>3920</td>\n",
       "      <td>1.231610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nobelfoundation/nobel-laureates</th>\n",
       "      <td>Nobel Laureates, 1901-Present</td>\n",
       "      <td>Which country has won the most prizes in each ...</td>\n",
       "      <td>3192</td>\n",
       "      <td>6.776300e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            title  \\\n",
       "ref                                                                                                 \n",
       "jealousleopard/goodreadsbooks                                                     Goodreads-books   \n",
       "uciml/zoo-animal-classification                                         Zoo Animal Classification   \n",
       "yekenot/fasttext-crawl-300d-2m                                             FastText crawl 300d 2M   \n",
       "rtatman/sentiment-lexicons-for-81-languages                   Sentiment Lexicons for 81 Languages   \n",
       "rtatman/glove-global-vectors-for-word-represent...  GloVe: Global Vectors for Word Representation   \n",
       "mozillaorg/common-voice                                                              Common Voice   \n",
       "arathee2/demonetization-in-india-twitter-data                Demonetization in India Twitter Data   \n",
       "eibriel/rdany-conversations                                                            rDany Chat   \n",
       "mrisdal/2016-us-presidential-debates                                 2016 US Presidential Debates   \n",
       "nobelfoundation/nobel-laureates                                     Nobel Laureates, 1901-Present   \n",
       "\n",
       "                                                                                             subtitle  \\\n",
       "ref                                                                                                     \n",
       "jealousleopard/goodreadsbooks                       comprehensive list of all books listed in good...   \n",
       "uciml/zoo-animal-classification                     Use Machine Learning Methods to Correctly Clas...   \n",
       "yekenot/fasttext-crawl-300d-2m                      2 million word vectors trained on Common Crawl...   \n",
       "rtatman/sentiment-lexicons-for-81-languages         Sentiment Polarity Lexicons (Positive vs. Nega...   \n",
       "rtatman/glove-global-vectors-for-word-represent...  Pre-trained word vectors from Wikipedia 2014 +...   \n",
       "mozillaorg/common-voice                             500 hours of speech recordings, with speaker d...   \n",
       "arathee2/demonetization-in-india-twitter-data       Data extracted from Twitter regarding the rece...   \n",
       "eibriel/rdany-conversations                         157 chats & 6300+ messages with a (fake) virtu...   \n",
       "mrisdal/2016-us-presidential-debates                Full transcripts of the face-off between Clint...   \n",
       "nobelfoundation/nobel-laureates                     Which country has won the most prizes in each ...   \n",
       "\n",
       "                                                    downloadCount  \\\n",
       "ref                                                                 \n",
       "jealousleopard/goodreadsbooks                               23640   \n",
       "uciml/zoo-animal-classification                             16597   \n",
       "yekenot/fasttext-crawl-300d-2m                               8275   \n",
       "rtatman/sentiment-lexicons-for-81-languages                  7960   \n",
       "rtatman/glove-global-vectors-for-word-represent...           7432   \n",
       "mozillaorg/common-voice                                      6075   \n",
       "arathee2/demonetization-in-india-twitter-data                5761   \n",
       "eibriel/rdany-conversations                                  3983   \n",
       "mrisdal/2016-us-presidential-debates                         3920   \n",
       "nobelfoundation/nobel-laureates                              3192   \n",
       "\n",
       "                                                      totalBytes  \n",
       "ref                                                               \n",
       "jealousleopard/goodreadsbooks                       6.373380e+05  \n",
       "uciml/zoo-animal-classification                     1.898000e+03  \n",
       "yekenot/fasttext-crawl-300d-2m                      1.545552e+09  \n",
       "rtatman/sentiment-lexicons-for-81-languages         1.621755e+06  \n",
       "rtatman/glove-global-vectors-for-word-represent...  4.801726e+08  \n",
       "mozillaorg/common-voice                             1.293147e+10  \n",
       "arathee2/demonetization-in-india-twitter-data       9.195780e+05  \n",
       "eibriel/rdany-conversations                         9.167240e+05  \n",
       "mrisdal/2016-us-presidential-debates                1.231610e+05  \n",
       "nobelfoundation/nobel-laureates                     6.776300e+04  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results.values())[['ref', 'title', 'subtitle', 'downloadCount', 'totalBytes']]\n",
    "df = df.set_index('ref').sort_values('downloadCount', ascending=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:53:09.556149Z",
     "start_time": "2020-09-23T17:53:09.538156Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(df.head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.meta` is your access to metadata about datasets. \n",
    "\n",
    "It works the same way things work with the zips of datasets: It will:\n",
    "- list: will list locally store dataset meta information (in location specified by `s.meta_dir`)\n",
    "- get: when a value (metadata dict) is requested, (1) the key is searched locally first, and if not found, (2) will request it remotely (through the kaggle api), and (3) the value will be cached (stored) locally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cached search info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, it's not all: `KaggleDatasets` will (by default) also cache these results locally in individual json files.\n",
    "\n",
    "Where? Ask `meta_dir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:31:49.638906Z",
     "start_time": "2020-09-23T17:31:49.619640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/D/Dropbox/_odata/kaggle/meta'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.meta_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access these files with your favorite dict-like interface, through the `.meta` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:28:13.233122Z",
     "start_time": "2020-09-23T17:28:13.189703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:36:48.873333Z",
     "start_time": "2020-09-23T17:36:48.772768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emmabel/word-occurrences-in-mr-robot',\n",
       " 'bitsnpieces/covid19-country-data',\n",
       " 'johnwdata/coronavirus-covid19-cases-by-us-state',\n",
       " 'johnwdata/coronavirus-covid19-cases-by-us-county',\n",
       " 'andradaolteanu/bing-nrc-afinn-lexicons',\n",
       " 'rahulloha/covid19',\n",
       " 'nltkdata/word2vec-sample']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s.meta)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:36:49.432298Z",
     "start_time": "2020-09-23T17:36:49.404143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creatorName': 'Emma',\n",
      " 'creatorUrl': 'emmabel',\n",
      " 'currentVersionNumber': 1,\n",
      " 'description': None,\n",
      " 'downloadCount': 116,\n",
      " 'files': [],\n",
      " 'id': 4288,\n",
      " 'isFeatured': False,\n",
      " 'isPrivate': False,\n",
      " 'isReviewed': False,\n",
      " 'kernelCount': 1,\n",
      " 'lastUpdated': '2017-11-09T18:30:15.733Z',\n",
      " 'licenseName': 'CC0: Public Domain',\n",
      " 'ownerName': 'Emma',\n",
      " 'ownerRef': 'emmabel',\n",
      " 'ref': 'emmabel/word-occurrences-in-mr-robot',\n",
      " 'subtitle': \"Find out F-Society's favorite lingo\",\n",
      " 'tags': [{'competitionCount': 0,\n",
      "           'datasetCount': 7525,\n",
      "           'description': 'Activities that holds the attention and interest of '\n",
      "                          'an audience, or gives pleasure and delight. It can '\n",
      "                          'be an idea or a task, but is more likely to be one '\n",
      "                          'of the activities or events that have developed '\n",
      "                          'over thousands of years specifically for the '\n",
      "                          \"purpose of keeping an audience's attention.\",\n",
      "           'fullPath': 'topic > arts and entertainment',\n",
      "           'isAutomatic': False,\n",
      "           'name': 'arts and entertainment',\n",
      "           'ref': 'arts and entertainment',\n",
      "           'scriptCount': 35,\n",
      "           'totalCount': 7560},\n",
      "          {'competitionCount': 0,\n",
      "           'datasetCount': 1227,\n",
      "           'description': 'One of the hallmarks of intelligence is the use of '\n",
      "                          'games and toys to occupy free time and develop '\n",
      "                          \"intellectually. Often stored in Mom's basement.\",\n",
      "           'fullPath': 'topic > culture and humanities > games',\n",
      "           'isAutomatic': False,\n",
      "           'name': 'games',\n",
      "           'ref': 'games',\n",
      "           'scriptCount': 40,\n",
      "           'totalCount': 1267}],\n",
      " 'title': 'Word Occurrences in Mr. Robot',\n",
      " 'topicCount': 0,\n",
      " 'totalBytes': 119466,\n",
      " 'url': 'https://www.kaggle.com/emmabel/word-occurrences-in-mr-robot',\n",
      " 'usabilityRating': 0.7058824,\n",
      " 'versions': [],\n",
      " 'viewCount': 1028,\n",
      " 'voteCount': 5}\n"
     ]
    }
   ],
   "source": [
    "pprint(s.meta['emmabel/word-occurrences-in-mr-robot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if you want to search locally for information (again, information about your searches, not your data zips!), you can get them in a `DataFrame` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:48:24.771065Z",
     "start_time": "2020-09-23T17:48:24.336350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>tags</th>\n",
       "      <th>creatorName</th>\n",
       "      <th>creatorUrl</th>\n",
       "      <th>totalBytes</th>\n",
       "      <th>url</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>...</th>\n",
       "      <th>datasetId</th>\n",
       "      <th>datasetSlug</th>\n",
       "      <th>ownerUser</th>\n",
       "      <th>totalViews</th>\n",
       "      <th>totalVotes</th>\n",
       "      <th>totalDownloads</th>\n",
       "      <th>licenses</th>\n",
       "      <th>keywords</th>\n",
       "      <th>collaborators</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4288.0</td>\n",
       "      <td>emmabel/word-occurrences-in-mr-robot</td>\n",
       "      <td>Find out F-Society's favorite lingo</td>\n",
       "      <td>[{'ref': 'arts and entertainment', 'competitio...</td>\n",
       "      <td>Emma</td>\n",
       "      <td>emmabel</td>\n",
       "      <td>1.194660e+05</td>\n",
       "      <td>https://www.kaggle.com/emmabel/word-occurrence...</td>\n",
       "      <td>2017-11-09T18:30:15.733Z</td>\n",
       "      <td>116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576036.0</td>\n",
       "      <td>bitsnpieces/covid19-country-data</td>\n",
       "      <td>Country level metadata that includes temperatu...</td>\n",
       "      <td>[{'ref': 'global', 'competitionCount': 0, 'dat...</td>\n",
       "      <td>Patrick</td>\n",
       "      <td>bitsnpieces</td>\n",
       "      <td>1.908210e+05</td>\n",
       "      <td>https://www.kaggle.com/bitsnpieces/covid19-cou...</td>\n",
       "      <td>2020-05-03T23:51:55.5Z</td>\n",
       "      <td>939.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>575937.0</td>\n",
       "      <td>johnwdata/coronavirus-covid19-cases-by-us-state</td>\n",
       "      <td>NYTimes Coronavirus Dataset</td>\n",
       "      <td>[{'ref': 'earth and nature', 'competitionCount...</td>\n",
       "      <td>John Wackerow</td>\n",
       "      <td>johnwdata</td>\n",
       "      <td>8.258200e+04</td>\n",
       "      <td>https://www.kaggle.com/johnwdata/coronavirus-c...</td>\n",
       "      <td>2020-09-23T12:43:05.76Z</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>575883.0</td>\n",
       "      <td>johnwdata/coronavirus-covid19-cases-by-us-county</td>\n",
       "      <td>NYTimes Coronavirus Dataset</td>\n",
       "      <td>[{'ref': 'earth and nature', 'competitionCount...</td>\n",
       "      <td>John Wackerow</td>\n",
       "      <td>johnwdata</td>\n",
       "      <td>3.508189e+06</td>\n",
       "      <td>https://www.kaggle.com/johnwdata/coronavirus-c...</td>\n",
       "      <td>2020-07-23T18:47:16.543Z</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>507452.0</td>\n",
       "      <td>andradaolteanu/bing-nrc-afinn-lexicons</td>\n",
       "      <td>the lexicons are in CSV format</td>\n",
       "      <td>[{'ref': 'earth and nature', 'competitionCount...</td>\n",
       "      <td>Andrada Olteanu</td>\n",
       "      <td>andradaolteanu</td>\n",
       "      <td>8.396500e+04</td>\n",
       "      <td>https://www.kaggle.com/andradaolteanu/bing-nrc...</td>\n",
       "      <td>2020-02-09T18:39:13.343Z</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>839.0</td>\n",
       "      <td>nobelfoundation/nobel-laureates</td>\n",
       "      <td>Which country has won the most prizes in each ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Abigail Larion</td>\n",
       "      <td>abigaillarion</td>\n",
       "      <td>6.776300e+04</td>\n",
       "      <td>https://www.kaggle.com/nobelfoundation/nobel-l...</td>\n",
       "      <td>2017-02-16T00:31:00.993Z</td>\n",
       "      <td>3192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>110364.0</td>\n",
       "      <td>fourtonfish/hello-salut</td>\n",
       "      <td>Dataset of translations of the word \"hello\" to...</td>\n",
       "      <td>[{'ref': 'languages', 'competitionCount': 3, '...</td>\n",
       "      <td>Stefan Bohacek</td>\n",
       "      <td>fourtonfish</td>\n",
       "      <td>6.600000e+03</td>\n",
       "      <td>https://www.kaggle.com/fourtonfish/hello-salut</td>\n",
       "      <td>2019-03-10T22:32:44.603Z</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>540160.0</td>\n",
       "      <td>guenthermi/facete</td>\n",
       "      <td>Dataset for Domain-Specific Word Embedding Eva...</td>\n",
       "      <td>[{'ref': 'internet', 'competitionCount': 18, '...</td>\n",
       "      <td>Michael Günther</td>\n",
       "      <td>guenthermi</td>\n",
       "      <td>1.300565e+07</td>\n",
       "      <td>https://www.kaggle.com/guenthermi/facete</td>\n",
       "      <td>2020-03-04T15:03:24.507Z</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>688051.0</td>\n",
       "      <td>bcgvaccine/hackathon</td>\n",
       "      <td>Improve BCG Data and Provide Insights to \"BCG ...</td>\n",
       "      <td>[{'ref': 'business', 'competitionCount': 2, 'd...</td>\n",
       "      <td>Radoslav Kirkov</td>\n",
       "      <td>rkirkov</td>\n",
       "      <td>4.695259e+09</td>\n",
       "      <td>https://www.kaggle.com/bcgvaccine/hackathon</td>\n",
       "      <td>2020-09-22T17:16:38.747Z</td>\n",
       "      <td>283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>545752.0</td>\n",
       "      <td>dsari1972/convid-population</td>\n",
       "      <td>Populations of Province/State of Countries aff...</td>\n",
       "      <td>[{'ref': 'health', 'competitionCount': 2, 'dat...</td>\n",
       "      <td>Dimitris Sarigiannis</td>\n",
       "      <td>dsari1972</td>\n",
       "      <td>4.736000e+04</td>\n",
       "      <td>https://www.kaggle.com/dsari1972/convid-popula...</td>\n",
       "      <td>2020-03-08T20:09:07.257Z</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               ref  \\\n",
       "0      4288.0              emmabel/word-occurrences-in-mr-robot   \n",
       "1    576036.0                  bitsnpieces/covid19-country-data   \n",
       "2    575937.0   johnwdata/coronavirus-covid19-cases-by-us-state   \n",
       "3    575883.0  johnwdata/coronavirus-covid19-cases-by-us-county   \n",
       "4    507452.0            andradaolteanu/bing-nrc-afinn-lexicons   \n",
       "..        ...                                               ...   \n",
       "353     839.0                   nobelfoundation/nobel-laureates   \n",
       "354  110364.0                           fourtonfish/hello-salut   \n",
       "355  540160.0                                 guenthermi/facete   \n",
       "356  688051.0                              bcgvaccine/hackathon   \n",
       "357  545752.0                       dsari1972/convid-population   \n",
       "\n",
       "                                              subtitle  \\\n",
       "0                  Find out F-Society's favorite lingo   \n",
       "1    Country level metadata that includes temperatu...   \n",
       "2                          NYTimes Coronavirus Dataset   \n",
       "3                          NYTimes Coronavirus Dataset   \n",
       "4                       the lexicons are in CSV format   \n",
       "..                                                 ...   \n",
       "353  Which country has won the most prizes in each ...   \n",
       "354  Dataset of translations of the word \"hello\" to...   \n",
       "355  Dataset for Domain-Specific Word Embedding Eva...   \n",
       "356  Improve BCG Data and Provide Insights to \"BCG ...   \n",
       "357  Populations of Province/State of Countries aff...   \n",
       "\n",
       "                                                  tags           creatorName  \\\n",
       "0    [{'ref': 'arts and entertainment', 'competitio...                  Emma   \n",
       "1    [{'ref': 'global', 'competitionCount': 0, 'dat...               Patrick   \n",
       "2    [{'ref': 'earth and nature', 'competitionCount...         John Wackerow   \n",
       "3    [{'ref': 'earth and nature', 'competitionCount...         John Wackerow   \n",
       "4    [{'ref': 'earth and nature', 'competitionCount...       Andrada Olteanu   \n",
       "..                                                 ...                   ...   \n",
       "353                                                 []        Abigail Larion   \n",
       "354  [{'ref': 'languages', 'competitionCount': 3, '...        Stefan Bohacek   \n",
       "355  [{'ref': 'internet', 'competitionCount': 18, '...       Michael Günther   \n",
       "356  [{'ref': 'business', 'competitionCount': 2, 'd...       Radoslav Kirkov   \n",
       "357  [{'ref': 'health', 'competitionCount': 2, 'dat...  Dimitris Sarigiannis   \n",
       "\n",
       "         creatorUrl    totalBytes  \\\n",
       "0           emmabel  1.194660e+05   \n",
       "1       bitsnpieces  1.908210e+05   \n",
       "2         johnwdata  8.258200e+04   \n",
       "3         johnwdata  3.508189e+06   \n",
       "4    andradaolteanu  8.396500e+04   \n",
       "..              ...           ...   \n",
       "353   abigaillarion  6.776300e+04   \n",
       "354     fourtonfish  6.600000e+03   \n",
       "355      guenthermi  1.300565e+07   \n",
       "356         rkirkov  4.695259e+09   \n",
       "357       dsari1972  4.736000e+04   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://www.kaggle.com/emmabel/word-occurrence...   \n",
       "1    https://www.kaggle.com/bitsnpieces/covid19-cou...   \n",
       "2    https://www.kaggle.com/johnwdata/coronavirus-c...   \n",
       "3    https://www.kaggle.com/johnwdata/coronavirus-c...   \n",
       "4    https://www.kaggle.com/andradaolteanu/bing-nrc...   \n",
       "..                                                 ...   \n",
       "353  https://www.kaggle.com/nobelfoundation/nobel-l...   \n",
       "354     https://www.kaggle.com/fourtonfish/hello-salut   \n",
       "355           https://www.kaggle.com/guenthermi/facete   \n",
       "356        https://www.kaggle.com/bcgvaccine/hackathon   \n",
       "357  https://www.kaggle.com/dsari1972/convid-popula...   \n",
       "\n",
       "                  lastUpdated  downloadCount  ...  datasetId datasetSlug  \\\n",
       "0    2017-11-09T18:30:15.733Z          116.0  ...        NaN         NaN   \n",
       "1      2020-05-03T23:51:55.5Z          939.0  ...        NaN         NaN   \n",
       "2     2020-09-23T12:43:05.76Z           59.0  ...        NaN         NaN   \n",
       "3    2020-07-23T18:47:16.543Z           37.0  ...        NaN         NaN   \n",
       "4    2020-02-09T18:39:13.343Z          135.0  ...        NaN         NaN   \n",
       "..                        ...            ...  ...        ...         ...   \n",
       "353  2017-02-16T00:31:00.993Z         3192.0  ...        NaN         NaN   \n",
       "354  2019-03-10T22:32:44.603Z          120.0  ...        NaN         NaN   \n",
       "355  2020-03-04T15:03:24.507Z           11.0  ...        NaN         NaN   \n",
       "356  2020-09-22T17:16:38.747Z          283.0  ...        NaN         NaN   \n",
       "357  2020-03-08T20:09:07.257Z           34.0  ...        NaN         NaN   \n",
       "\n",
       "    ownerUser totalViews totalVotes totalDownloads licenses  keywords  \\\n",
       "0         NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "1         NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "2         NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "3         NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "4         NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "..        ...        ...        ...            ...      ...       ...   \n",
       "353       NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "354       NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "355       NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "356       NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "357       NaN        NaN        NaN            NaN      NaN       NaN   \n",
       "\n",
       "    collaborators  data  \n",
       "0             NaN   NaN  \n",
       "1             NaN   NaN  \n",
       "2             NaN   NaN  \n",
       "3             NaN   NaN  \n",
       "4             NaN   NaN  \n",
       "..            ...   ...  \n",
       "353           NaN   NaN  \n",
       "354           NaN   NaN  \n",
       "355           NaN   NaN  \n",
       "356           NaN   NaN  \n",
       "357           NaN   NaN  \n",
       "\n",
       "[358 rows x 36 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(s.meta.values())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T17:53:00.513874Z",
     "start_time": "2020-09-23T17:53:00.496980Z"
    }
   },
   "outputs": [],
   "source": [
    "# t = df.head(10).dropna(axis=1)\n",
    "# del t['tags']\n",
    "# print(t.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: If you don't want all your search results to be cached you can just specify it.**\n",
    "\n",
    "```python\n",
    "s = KaggleDatasets(rootdir, cache_metas_on_search=False)  # make an instance\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The boring stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install haggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You'll need a kaggle api token to use this**\n",
    "\n",
    "If you do, you probably can just start using. \n",
    "\n",
    "If you don't got get one! Go see [this](https://github.com/Kaggle/kaggle-api) for detailed instructions, it essentially says:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## API credentials\n",
    "\n",
    "To use the Kaggle API, sign up for a Kaggle account at https://www.kaggle.com. \n",
    "Then go to the 'Account' tab of your user profile (`https://www.kaggle.com/<username>/account`) and select 'Create API Token'. \n",
    "This will trigger the download of `kaggle.json`, a file containing your API credentials. \n",
    "Place this file in the location `~/.kaggle/kaggle.json` (on Windows in the location `C:\\Users\\<Windows-username>\\.kaggle\\kaggle.json` - you can check the exact location, sans drive, with `echo %HOMEPATH%`). \n",
    "You can define a shell environment variable `KAGGLE_CONFIG_DIR` to change this location to `$KAGGLE_CONFIG_DIR/kaggle.json` (on Windows it will be `%KAGGLE_CONFIG_DIR%\\kaggle.json`).\n",
    "\n",
    "For your security, ensure that other users of your computer do not have read access to your credentials. On Unix-based systems you can do this with the following command: \n",
    "\n",
    "`chmod 600 ~/.kaggle/kaggle.json`\n",
    "\n",
    "You can also choose to export your Kaggle username and token to the environment:\n",
    "\n",
    "```bash\n",
    "export KAGGLE_USERNAME=datadinosaur\n",
    "export KAGGLE_KEY=xxxxxxxxxxxxxx\n",
    "```\n",
    "In addition, you can export any other configuration value that normally would be in\n",
    "the `$HOME/.kaggle/kaggle.json` in the format 'KAGGLE_<VARIABLE>' (note uppercase).  \n",
    "For example, if the file had the variable \"proxy\" you would export `KAGGLE_PROXY`\n",
    "and it would be discovered by the client.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F.A.Q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if I don't want a zip file anymore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just delete it, like you do with any file you don't want anymore. You know the one.\n",
    "\n",
    "Or... you can be cool and do `del s['owner/dataset']` for that key (note a key doesn't include the rootdir or the `.zip` extension), just like you would with a... `dict`, once again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do you have any jupyter notebooks demoing this.\n",
    "\n",
    "Sure, you can find some [here on github](https://github.com/otosense/haggle/tree/master/docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "172px",
    "left": "64px",
    "top": "110px",
    "width": "885px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

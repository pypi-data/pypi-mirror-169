Metadata-Version: 2.1
Name: stress-testing
Version: 0.1
Summary: A Stress Testing Experiment on Different Sequential Models
Author: Ipek Erdogan
Author-email: ipek.erdogan@boun.edu.tr
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy
Requires-Dist: torch

-----------------
Requirements
Python 3.8.11
numpy 1.21.5
torch 1.13.0.dev20220922
-----------------

-----------------
This package consists of 5 files:
train.py
test.py
dataset.py
models.py
evaluation.py
-----------------

-----------------
WARNINGS
1. For both of the scripts, there are default arguments. If you do not specify the argument it will run with the default ones. Both of the scripts (train.py test.py) requires some path information for reading/writing file/model processes.
2. I suggest you to create 2 directories under the path you are running this package: "data" and "saved_models". You can pass these directories as path information when needed. In terms of datasets you have two options in this package:
    a. Create your own dataset by un-commenting lines [30-33] in train.py
    b. Fill the directory "data" with the dataset I provided as supplementary material.
3. You always need to pass train/test data and label paths. Otherwise it won't work. Also in train.py, if you don't pass the directory path for saving the model, it won't save the model and it will continue training. 
If you are passing the model saving directory path as a parameter, please be sure that the directory is already there.
4. While evaluating a model with a test dataset by running test.py, if you want to use a custom test dataset please be sure that:
    a. You provide separate files for data and labels
    b. File formats are .npy
-----------------

-----------------
SCRIPTS
train.py:
You can
1) Train a sequential model (IRNN, GRU or LSTM) with a training dataset,
    Or create your own dataset and continue training with it
2) Evaluate the model performance with test dataset and
3) Save the model through this script.
How to run through the terminal?
    train.py -model MODEL_NAME -timesteps TIMESTEPS -epochs EPOCHS -lr LEARNING_RATE -g_clip GRADIENT_CLIPPING -train_data_path TRAIN_DATA_PATH -train_label_path TRAIN_LABEL_PATH -test_data_path TEST_DATA_PATH -test_label_path TEST_LABEL_PATH -model_save_path MODEL_SAVE_PATH
an example running command:
    train.py -model GRU -timesteps 150 -epochs 10 -lr 0.0001 -g_clip 10 -train_data_path /Users/ipek/stress_testing/data/train_data.npy -train_label_path /Users/ipek/stress_testing/data/train_labels.npy -test_data_path /Users/ipek/stress_testing/data/test_data.npy -test_label_path /Users/ipek/stress_testing/data/test_labels.npy -model_save_directory /Users/ipek/stress_testing/saved_models

test.py:
You can test a pre-trained model with (default) test dataset (or with the dataset you provided if you pass the path as arguments)
How to run through the terminal?
    test.py -model MODEL_NAME -timesteps TIMESTEPS -filepath FILE_PATH -datapath DATA_PATH -labelpath LABEL_PATH
an example running command:
    test.py -model GRU -timesteps 150 -filepath /Users/ipek/stress_testing/saved_models/gru_150_0.pt -datapath /Users/ipek/stress_testing/data/test_data.npy -labelpath /Users/ipek/stress_testing/data/test_labels.npy
-----------------

-----------------
MODULES
dataset.py:
Includes two methods:
    create_dataset: Creates the dataset according to the passed parameters such as number of datapoints, and sequence length.
    save_dataset: Saves numpy (data) arrays as .npy files

models.py:
Includes one class and two methods:
    Model: The model class which consists of an/a IRNN/GRU/LSTM and a Linear layer.
    init_weights: Initializes the model weights according to the parameter (layer) names.
    optimizer_to: Passes the optimizer to a device (CPU/CUDA etc.).

evaluation.py
Includes two methods:
    test_model: Testing the model with test_dataloader.
    load_checkpoint: Loading the model weights from a pre-saved model file.
-----------------

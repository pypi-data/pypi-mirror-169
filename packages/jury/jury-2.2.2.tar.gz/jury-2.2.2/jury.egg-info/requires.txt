click==8.0.4
evaluate<0.3,>=0.2.2
fire>=0.4.0
nltk<3.7.1,>=3.6.6
rouge-score==0.0.4
sklearn
tqdm
validators

[dev]
black==21.7b0
deepdiff==5.5.0
flake8==3.9.2
isort==5.9.2
pytest>=7.0.1
pytest-cov>=3.0.0
pytest-timeout>=2.1.0
sacrebleu>=2.0.0
bert_score==0.3.11
jiwer>=2.3.0
seqeval==1.2.2
sentencepiece==0.1.96
unbabel-comet>=1.1.2
fairseq==0.9.0
validators

[metrics]
sacrebleu>=2.0.0
bert_score==0.3.11
jiwer>=2.3.0
seqeval==1.2.2
sentencepiece==0.1.96
unbabel-comet>=1.1.2
fairseq==0.9.0
validators

[prism]
fairseq==0.9.0
validators

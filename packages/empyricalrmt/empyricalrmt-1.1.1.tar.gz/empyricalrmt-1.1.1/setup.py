# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['empyricalRMT', 'empyricalRMT.observables', 'empyricalRMT.signalproc']

package_data = \
{'': ['*']}

install_requires = \
['EMD-signal>=1.2.3,<2.0.0',
 'matplotlib>=3.5.3,<4.0.0',
 'numba>=0.56.2,<0.57.0',
 'numpy>=1.23.3,<2.0.0',
 'pandas>=1.4.4,<2.0.0',
 'pyod>=1.0.4,<2.0.0',
 'scikit-learn>=1.1.2,<2.0.0',
 'scipy>=1.9.1,<2.0.0',
 'seaborn>=0.12.0,<0.13.0',
 'statsmodels>=0.13.2,<0.14.0',
 'tqdm>=4.64.1,<5.0.0',
 'typing-extensions>=4.3.0,<5.0.0']

setup_kwargs = {
    'name': 'empyricalrmt',
    'version': '1.1.1',
    'description': 'Eigenvalue unfolding and spectral observable computation',
    'long_description': '[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7105502.svg)](https://doi.org/10.5281/zenodo.7105502)\n\n\n# empyricalRMT - Random Matrix Theory Tools for Python\n\nA python library for investigating some of the basic / classical elements of\nRandom Matrix Theory, including eigenvalue generation, trimming, unfolding and\ncomputation and plotting of some spectral observables.\n\n\n- [empyricalRMT - Random Matrix Theory Tools for Python](#empyricalrmt---random-matrix-theory-tools-for-python)\n- [Features](#features)\n  - [Easy Unfolding, Trimming and De-Trending](#easy-unfolding-trimming-and-de-trending)\n  - [Optimized Performance](#optimized-performance)\n    - [Spectral Observables](#spectral-observables)\n    - [GOE Eigenvalues](#goe-eigenvalues)\n- [Examples](#examples)\n- [Documentation](#documentation)\n- [Installation](#installation)\n  - [Pip](#pip)\n  - [Poetry](#poetry)\n  - [Development](#development)\n  - [Windows](#windows)\n- [Limitations](#limitations)\n\n# Features\n\n## Easy Unfolding, Trimming and De-Trending\n\nComparing actual eigenvalues to theory requires, in most cases, unfolding. This procedure\nis often ad hoc, poorly documented, and dramatically impacts conclusions about the nature\nof the systems under study.  With `empyricalRMT`, it is easy to unfold and visualize\ndifferent unfolding decisions:\n\n```python\nimport matplotlib.pyplot as plt\n\nfrom empyricalRMT.eigenvalues import Eigenvalues\nfrom empyricalRMT.smoother import SmoothMethod\n\neigs = Eigenvalues.generate(1000, kind="goe")\nunfoldings = {\n    "Exponential": eigs.unfold(smoother=SmoothMethod.Exponential),\n    "Polynomial": eigs.unfold(smoother=SmoothMethod.Polynomial, degree=5),\n    "Gompertz": eigs.unfold(smoother=SmoothMethod.Gompertz),\n    "GOE": eigs.unfold(smoother=SmoothMethod.GOE),\n}\nN = len(unfoldings)\n    fig, axes = plt.subplots(ncols=3, nrows=N)\n    for i, (label, unfolded) in enumerate(unfoldings.items()):\n        title = f"{label} Unfolding"\n        unfolded.plot_nnsd(\n            title=title,\n            brody=True,\n            brody_fit="mle",\n            ensembles=["goe", "poisson"],\n            fig=fig,\n            axes=axes[i][0],\n        )\n        unfolded.plot_spectral_rigidity(title=title, ensembles=["goe"], fig=fig, axes=axes[i][1])\n        unfolded.plot_level_variance(title=title, ensembles=["goe"], fig=fig, axes=axes[i][2])\n        axes[i][0].legend().set_visible(False) if i != 0 else None\n        axes[i][1].legend().set_visible(False) if i != 0 else None\nplt.show()\n```\n\n![Comparing unfoldings](readme/unfold_compare.png)\n\n\n\n## Optimized Performance\n\n### Spectral Observables\n\nFor a sample of unfolded eigenvalues, computation of the spectral rigidity,\n\n$$ \\Delta_3(L) = \\left\\langle \\min_{A, B} \\frac{1}{L} \\int_c^{c+L} \\Big( \\eta(\\lambda) - A \\lambda - B \\Big)^2 d\\lambda \\right\\rangle_c $$\n\nand level number variance\n\n$$ \\Sigma^2(L) = \\big\\langle  \\eta^2(L, \\lambda) \\big\\rangle -   \\big\\langle  \\eta(L, \\lambda) \\big\\rangle^2 $$\n\nrequires some non-trivial Monte-Carlo computations that border on intractable\nwith plain Python and even NumPy / scikit-learn / scipy. `empyricalRMT` uses\nNumba and carefully written code to dramatically speed-up and parallelize the\ncomputation of these metrics:\n\n```python\nimport numpy as np\nfrom timeit import repeat\nfrom empyricalRMT.eigenvalues import Eigenvalues\n\nunfolded = Eigenvalues.generate(5000, kind="goe").unfold(smoother="goe")\nL = np.arange(2, 50, 1, dtype=np.float64)\nresults = repeat(\n    "unfolded.spectral_rigidity(L)", number=10, globals=dict(unfolded=unfolded, L=L), repeat=10\n)\nprint(f"Mean: {np.mean(results):0.2f}s. Range: [{np.min(results):0.2f}, {np.max(results):0.2f}]")\n\n# Level number variance is far more variable for larger L, so use a smaller range here\nL = np.arange(2, 20, 1, dtype=np.float64)\nresults = repeat(\n    "unfolded.level_variance(L)", number=10, globals=dict(unfolded=unfolded, L=L), repeat=10\n)\nprint(\n    f"Mean: {np.mean(results):0.2f}s. Range: [{np.min(results):0.2f}, {np.max(results):0.2f}]"\n)\n```\n```\nMean: 3.18s. Range: [2.88, 3.62]\nMean: 3.56s. Range: [3.08, 6.46]\n```\n\n### GOE Eigenvalues\n\nSample eigenvalues from *large* GOE matrices (provided they can fit in memory) ***fast*** via\n[equivalently distributed tridiagonal matrices](https://dspace.mit.edu/handle/1721.1/115982):\n\n```python\nfrom empyricalRMT.construct import generate_eigs\n\neigs = generate_eigs(matsize=30000, kind="goe", log_time=True)\n\n""" Output:\n>>> 15:40:39 (Mar10) -- computing eigenvalues...\n>>> 15:41:05 (Mar10) -- computed eigenvalues.\n"""\n```\nE.g. under 30 seconds (Processor: 4-core / 8-threads, Intel(R)\nXeon(R) CPU E3-1575M v5 @ 3.00GHz).\n\n\n\n# Examples\n\nSample a random GOE matrix and investigate some basic properties:\n\n```python\nimport numpy as np\n\nfrom empyricalRMT._types import MatrixKind\nfrom empyricalRMT.eigenvalues import Eigenvalues\nfrom empyricalRMT.smoother import SmoothMethod\n\n# generate eigenvalues from a 2000x2000 sample from the Gaussian Orthogonal Ensemble\neigs = Eigenvalues.generate(matsize=2000, kind=MatrixKind.GOE)\n# unfold "analytically" using Wigner semi-circle\nunfolded = eigs.unfold(smoother=SmoothMethod.GOE)\n# visualize core spectral observables and unfolding fit\nunfolded.plot_observables(\n    rigidity_L=np.arange(2, 20, 0.5),\n    levelvar_L=np.arange(2, 20, 0.5),\n    title="GOE Spectral Observables - Analytic Unfolding",\n)\n```\n\n![Spectral observables](readme/observables.png)\n\n\nPlot some classic observables and compare to theory:\n\n```python\nimport numpy as np\n\nfrom empyricalRMT._types import MatrixKind\nfrom empyricalRMT.eigenvalues import Eigenvalues\nfrom empyricalRMT.smoother import SmoothMethod\n\n# generate eigenvalues from a 2000x2000 sample from the Gaussian Orthogonal Ensemble\neigs = Eigenvalues.generate(matsize=5000, kind=MatrixKind.GOE)\nensembles = ["poisson", "goe"]  # theoretically expected curves to plot\nunfolded.plot_nnsd(ensembles=ensembles)  # nearest neighbours spacings\nunfolded.plot_nnnsd(ensembles=["goe"])  # next-nearest neighbours spacings\nunfolded.plot_spectral_rigidity(ensembles=ensembles)\nunfolded.plot_level_variance(ensembles=ensembles)\n```\n\n![nnsd](readme/nnsd.png)\n![nnnsd](readme/nnnsd.png)\n![rigidity](readme/rigidity.png)\n![variance](readme/variance.png)\n\nVisually inspect / detect a questionable unfolding fit:\n\n```python\nimport matplotlib.pyplot as plt\n\nfrom empyricalRMT.eigenvalues import Eigenvalues\nfrom empyricalRMT.smoother import SmoothMethod\n\n# generate time series data\nT = np.random.standard_normal([1000, 250])\neigs = Eigenvalues.from_time_series(T, trim_zeros=False)\n\nexp_unfolded = eigs.unfold(smoother=SmoothMethod.Exponential)\npoly_unfolded = eigs.unfold(smoother=SmoothMethod.Polynomial, degree=5)\n\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\nexp_unfolded.plot_fit(fig=fig, axes=ax1, title="Exponential Unfolding")\npoly_unfolded.plot_fit(fig=fig, axes=ax2, title="Polynomial Degree 5 Unfolding")\nplt.show()\n```\n\n![bad fit](readme/unfoldfit.png)\n\n\n\n\n\n# Documentation\n\nThe [source\ncode](https://github.com/stfxecutables/empyricalRMT/tree/master/empyricalRMT)\naims to be well documented, and is the sole documentation for the project. If\nyou are using Python interactively (e.g. in a Jupyter notebook or REPL) then\nthese comments are quickly available by calling `help(rmt_object)`. If youare\nusing a decent IDE or editor with appropriate extensions (e.g. PyCharm, VSCode,\nmodern Jupyter) you should be able to see the documentation on mouse hover or\nvia your editor shortcuts (e.g. Go To Definition).\n\nMostly, you just want import `empyricalRMT.eigenvalues.Eigenvalues` and use\neither `Eigenvalues.generate()`  to get fresh random eigenvalues, or\n`Eigenvalues(eigs)` for some `ArrayLike` `eigs`. Trimming and unfolding\nmethods are available on `Eigenvalues` instances, and `Eigenvalues.unfold()`\ngives you an `empyricalRMT.unfold.Unfolded` instance, which has methods for\nvisualization and/or computation of spectral observables.\n\nOtherwise, functional forms of core functions for computing spectral observables\nare located in `empyricalRMT.observables`, if you just want to pass in raw\nNumPy arrays and get e.g. the spectral rigidity or level number variance.\n\n\n# Installation\n\n\n## Pip\n\n```sh\npip install empyricalRMT\n```\n\n## Poetry\n\nIn your project using [Poetry](https://python-poetry.org):\n\n```sh\npoetry add empyricalRMT && poetry install\n```\n\n## Development\n\n```sh\ngit clone https://github.com/stfxecutables/empyricalRMT\ncd empyricalRMT\npoetry install --with dev\npoetry shell\n```\n\nRun tests with `pytest`.\n\n## Windows\n\nNote this library is completely untested on Windows, but *might* work, if the\ndependencies also work on Windows. I\'ve tried to use practices that have led\nto successful portability to Windows in the past, and there is nothing *too*\nfancy going on here, but it still very likely something will break on Windows.\n\n\n# Limitations\n\nThis library was and is being developed on a reasonably decent machine (4 cores\n/ 8 threads, 3.00GHz, 64GB RAM) that is currently running Ubuntu 18.04 LTS. Out\nof convenience, I have used Numba, but I know that this is not the most portable\nsolution available, and may result in some issues.\n\nDefault values for most parameters were chosen because they provided reasonably\naccurate results (e.g. when compared to as predicted by theory) in reasonable\namounts of time on *this machine*. I have tested the library on my old 2015\nMacBook, and the defaults seem *okay*, but it is possible that they may not work\nwell on your machine, especially with regards to memory.\n\nRMT results are theoretical, and many results only hold for real numbers, as N\napproaches infinity. In practice, it seems that floating-point precision issues\n(whether in numerical integration, solving of eigenproblems, or in the\nconvergence of some of the stochastic methods used in this library) plus the\nreality of working with finite matrices means that there are significant limits\non the extent to which simulations agree with theory, especially when looking at\nlong-range spectral observables (e.g. spectral rigidity or level number variance\nfor L > 20) and when matrices are small (N < 2000).\n\nFinally, I am just a dabbler in RMT. I have tried to limit myself to\nimplementing only aspects I feel I understand, but I may have made some basic\nerrors in implementation or understanding at some point. If you notice any\nissues or mistakes, corrections are always warmly welcomed!\n',
    'author': 'Derek M Berger',
    'author_email': 'dmberger.dev@gmail.com',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'None',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.10,<3.12',
}


setup(**setup_kwargs)

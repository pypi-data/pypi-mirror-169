{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QmeBezYKceQ1"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from packaging.version import Version\n",
        "\n",
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "from spacy.training.example import Example\n",
        "\n",
        "import newron.spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqW47dpDdHnP",
        "outputId": "a537ecb8-cc32-4b2d-9c0f-b0218a071ac7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='mlflow-artifacts:/48', experiment_id='48', lifecycle_stage='active', name='SpacyExample', tags={}>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "remote_server_uri = SERVER_URI # set to your server URI\n",
        "newron.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env\n",
        "exp_name = \"SpacyExample\" # set your experiment name\n",
        "newron.set_experiment(exp_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dkeel-5Hcgj8"
      },
      "outputs": [],
      "source": [
        "IS_SPACY_VERSION_NEWER_THAN_OR_EQUAL_TO_3_0_0 = Version(spacy.__version__) >= Version(\"3.0.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w8hw5ksnch7I"
      },
      "outputs": [],
      "source": [
        "# training data\n",
        "TRAIN_DATA = [\n",
        "    (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
        "    (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AnC895HclcU",
        "outputId": "705cdeea-cf27-4b16-9d01-6f7fdb13781d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 15.053031861782074}\n",
            "Losses {'ner': 13.220588386058807}\n",
            "Losses {'ner': 12.571981489658356}\n",
            "Losses {'ner': 10.113959968090057}\n",
            "Losses {'ner': 7.883271664381027}\n",
            "Losses {'ner': 6.2573287934064865}\n",
            "Losses {'ner': 5.980585306882858}\n",
            "Losses {'ner': 5.139594436157495}\n",
            "Losses {'ner': 4.2203461427707225}\n",
            "Losses {'ner': 7.436829994228901}\n",
            "Losses {'ner': 6.766827849991387}\n",
            "Losses {'ner': 5.3287234820418234}\n",
            "Losses {'ner': 3.131577859574463}\n",
            "Losses {'ner': 3.355524822487496}\n",
            "Losses {'ner': 1.3667628129478544}\n",
            "Losses {'ner': 0.880070379236713}\n",
            "Losses {'ner': 0.4369672241155058}\n",
            "Losses {'ner': 0.30358853541110875}\n",
            "Losses {'ner': 0.0638207234442234}\n",
            "Losses {'ner': 0.0067083810451435966}\n",
            "Losses {'ner': 0.00010123948069917788}\n",
            "Losses {'ner': 3.7485692723882025e-05}\n",
            "Losses {'ner': 1.4947613554250339e-05}\n",
            "Losses {'ner': 7.1221805289165e-07}\n",
            "Losses {'ner': 2.5979704925023495e-07}\n",
            "Losses {'ner': 1.3994837795182e-07}\n",
            "Losses {'ner': 3.239396012715066e-08}\n",
            "Losses {'ner': 1.8645651549526414e-08}\n",
            "Losses {'ner': 1.7318247807960566e-06}\n",
            "Losses {'ner': 3.170863504529777e-08}\n",
            "Losses {'ner': 3.673509744082194e-08}\n",
            "Losses {'ner': 5.813775882257771e-09}\n",
            "Losses {'ner': 2.9143978220615847e-07}\n",
            "Losses {'ner': 1.073017641436253e-08}\n",
            "Losses {'ner': 1.8667093417054338e-08}\n",
            "Losses {'ner': 1.4904716488989277e-09}\n",
            "Losses {'ner': 3.645543231949373e-10}\n",
            "Losses {'ner': 1.9913292014311153e-09}\n",
            "Losses {'ner': 5.272247321201238e-10}\n",
            "Losses {'ner': 2.2026440152226587e-08}\n",
            "Losses {'ner': 1.0498978292093852e-09}\n",
            "Losses {'ner': 1.5262864740826085e-09}\n",
            "Losses {'ner': 1.2726737310587504e-09}\n",
            "Losses {'ner': 2.4903188046709567e-09}\n",
            "Losses {'ner': 2.932081117898238e-08}\n",
            "Losses {'ner': 3.400568240117098e-10}\n",
            "Losses {'ner': 1.0587477661084543e-08}\n",
            "Losses {'ner': 1.3122115641679123e-09}\n",
            "Losses {'ner': 4.858443245838894e-09}\n",
            "Losses {'ner': 8.193418796647179e-10}\n",
            "Losses {'ner': 1.3700567421595842e-09}\n",
            "Losses {'ner': 8.362085587453913e-10}\n",
            "Losses {'ner': 1.990364646476857e-08}\n",
            "Losses {'ner': 2.1185211969067352e-10}\n",
            "Losses {'ner': 3.764294592315887e-10}\n",
            "Losses {'ner': 3.5748519315462876e-09}\n",
            "Losses {'ner': 6.173036544388562e-10}\n",
            "Losses {'ner': 2.608324664308356e-09}\n",
            "Losses {'ner': 1.9098954006848964e-09}\n",
            "Losses {'ner': 3.70048535420241e-08}\n",
            "Losses {'ner': 7.896494091852331e-09}\n",
            "Losses {'ner': 2.148459868619871e-09}\n",
            "Losses {'ner': 2.0828504450009264e-10}\n",
            "Losses {'ner': 1.4474642753476458e-09}\n",
            "Losses {'ner': 2.445155929231565e-10}\n",
            "Losses {'ner': 8.57355288175309e-10}\n",
            "Losses {'ner': 8.393313462493726e-07}\n",
            "Losses {'ner': 4.291570955693855e-08}\n",
            "Losses {'ner': 1.196857898684022e-09}\n",
            "Losses {'ner': 2.0944691073340028e-10}\n",
            "Losses {'ner': 3.171926030462273e-08}\n",
            "Losses {'ner': 3.537234314359459e-09}\n",
            "Losses {'ner': 1.3749257933296297e-08}\n",
            "Losses {'ner': 1.0032456093922302e-10}\n",
            "Losses {'ner': 4.5635927081274954e-08}\n",
            "Losses {'ner': 3.1439744534655237e-09}\n",
            "Losses {'ner': 3.245801352139172e-10}\n",
            "Losses {'ner': 1.0315929585378546e-09}\n",
            "Losses {'ner': 2.8790464559543616e-10}\n",
            "Losses {'ner': 8.607901701663928e-10}\n",
            "Losses {'ner': 1.0018594536941228e-09}\n",
            "Losses {'ner': 9.195231166712192e-10}\n",
            "Losses {'ner': 2.974175407045527e-07}\n",
            "Losses {'ner': 5.663385680245446e-10}\n",
            "Losses {'ner': 9.581764284255307e-09}\n",
            "Losses {'ner': 4.671342333334728e-11}\n",
            "Losses {'ner': 1.4814518109362742e-09}\n",
            "Losses {'ner': 4.177317900711738e-10}\n",
            "Losses {'ner': 1.5944531838855206e-08}\n",
            "Losses {'ner': 1.6309459747054243e-07}\n",
            "Losses {'ner': 1.8100529281395194e-09}\n",
            "Losses {'ner': 5.010950822736729e-10}\n",
            "Losses {'ner': 2.033840229102926e-10}\n",
            "Losses {'ner': 1.6775131136709094e-08}\n",
            "Losses {'ner': 1.0212419149590012e-09}\n",
            "Losses {'ner': 1.7154250608472923e-09}\n",
            "Losses {'ner': 7.341627447932768e-10}\n",
            "Losses {'ner': 1.238784780890984e-08}\n",
            "Losses {'ner': 1.3893585567294925e-10}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022/08/08 12:53:17 WARNING mlflow.spacy: Generating only the spacy flavor for the provided spacy model. This means the model can be loaded back via `mlflow.spacy.load_model`, but cannot be loaded back using pyfunc APIs like `mlflow.pyfunc.load_model` or via the `mlflow models` CLI commands. MLflow will only generate the pyfunc flavor for spacy models containing a pipeline component that is an instance of spacy.pipeline.TextCategorizer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 1.1930844045320332e-09}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022/08/08 12:53:25 WARNING mlflow.utils.requirements_utils: Found tensorflow version (2.8.2+zzzcolab20220719082949) contains a local version label (+zzzcolab20220719082949). MLflow logged a pip requirement for this package as 'tensorflow==2.8.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2022/08/08 12:53:25 WARNING mlflow.utils.requirements_utils: Found torch version (1.12.0+cu113) contains a local version label (+cu113). MLflow logged a pip requirement for this package as 'torch==1.12.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2022/08/08 12:53:25 WARNING mlflow.utils.requirements_utils: Found jaxlib version (0.3.14+cuda11.cudnn805) contains a local version label (+cuda11.cudnn805). MLflow logged a pip requirement for this package as 'jaxlib==0.3.14' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved in run 47b0c92f89bb4545ad63d5f3ea741290\n",
            "Entities [('London', 'LOC'), ('Berlin', 'LOC')]\n",
            "Tokens [('I', '', 2), ('like', '', 2), ('London', 'LOC', 3), ('and', '', 2), ('Berlin', 'LOC', 3), ('.', '', 2)]\n",
            "Entities [('Shaka Khan', 'PERSON')]\n",
            "Tokens [('Who', '', 2), ('is', '', 2), ('Shaka', 'PERSON', 3), ('Khan', 'PERSON', 1), ('?', '', 2)]\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "if IS_SPACY_VERSION_NEWER_THAN_OR_EQUAL_TO_3_0_0:\n",
        "    ner = nlp.add_pipe(\"ner\", last=True)\n",
        "else:\n",
        "    ner = nlp.create_pipe(\"ner\")\n",
        "    nlp.add_pipe(ner, last=True)\n",
        "\n",
        "# add labels\n",
        "for _, annotations in TRAIN_DATA:\n",
        "    for ent in annotations.get(\"entities\"):\n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "params = {\"n_iter\": 100, \"drop\": 0.5}\n",
        "newron.log_params(params)\n",
        "\n",
        "nlp.begin_training()\n",
        "for itn in range(params[\"n_iter\"]):\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "    annotations_list = []\n",
        "    for batch in batches:\n",
        "        for text, annotations in batch:\n",
        "            try:\n",
        "            # create Example\n",
        "                doc = nlp.make_doc(text)\n",
        "                example = Example.from_dict(doc, annotations)\n",
        "                annotations_list.append(example)\n",
        "            except:\n",
        "                pass\n",
        "            nlp.update(\n",
        "                annotations_list,  # batch of texts\n",
        "                drop=0.2,  # dropout - make it harder to memorise data\n",
        "                losses=losses,\n",
        "                )\n",
        "    print(\"Losses\", losses)\n",
        "    newron.log_metrics(losses)\n",
        "\n",
        "# Log the spaCy model using mlflow\n",
        "newron.spacy.log_model(spacy_model=nlp, artifact_path=\"model\")\n",
        "model_uri = \"runs:/{run_id}/{artifact_path}\".format(\n",
        "    run_id=newron.active_run().info.run_id, artifact_path=\"model\"\n",
        ")\n",
        "\n",
        "print(\"Model saved in run %s\" % newron.active_run().info.run_uuid)\n",
        "\n",
        "# Load the model using mlflow and use it to predict data\n",
        "nlp2 = newron.spacy.load_model(model_uri=model_uri)\n",
        "for text, _ in TRAIN_DATA:\n",
        "    doc = nlp2(text)\n",
        "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "    print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "spacyExample.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
